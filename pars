import os
import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin

# Укажите URL страницы, с которой нужно скачать видео
url = "https://app.rule34.dev/hentai/0/score:%3E3+megumin+animated+"

# Папка для сохранения видео
output_dir = "videos"
os.makedirs(output_dir, exist_ok=True)

# Функция для скачивания видео по URL
def download_video(video_url, output_dir):
    local_filename = os.path.join(output_dir, video_url.split("/")[-1])
    with requests.get(video_url, stream=True) as r:
        r.raise_for_status()
        with open(local_filename, "wb") as f:
            for chunk in r.iter_content(chunk_size=8192):
                f.write(chunk)
    return local_filename

# Функция для парсинга страницы и извлечения видео URL
def parse_videos(url):
    response = requests.get(url)
    response.raise_for_status()

    soup = BeautifulSoup(response.content, "html.parser")
    video_urls = []

    # Ищем все теги <video>
    for video in soup.find_all("video"):
        # Получаем URL видео из атрибута <source>
        for source in video.find_all("source"):
            video_url = source.get("src")
            if video_url:
                video_urls.append(urljoin(url, video_url))

    # Ищем все ссылки на видеофайлы напрямую
    for link in soup.find_all("a"):
        href = link.get("href")
        if href and (".mp4" in href or ".webm" in href):
            video_urls.append(urljoin(url, href))

    return video_urls

# Получаем все видео URL со страницы
video_urls = parse_videos(url)

# Скачиваем все найденные видео
for video_url in video_urls:
    try:
        print(f"Downloading {video_url}")
        download_video(video_url, output_dir)
    except Exception as e:
        print(f"Failed to download {video_url}: {e}")
